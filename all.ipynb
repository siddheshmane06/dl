{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a872e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn\n",
    "#ciafr dataset\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "#activation = use to apply activation function\n",
    "#dropout = drops the unnecessary layer/neurons that are not in use\n",
    "#conv2d = extract the features from images\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
    "x_train.shape\n",
    "x_test.shape\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,(3,3),padding=\"same\",input_shape=x_train.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(32,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics='accuracy')\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train,10)\n",
    "y_train[0]\n",
    "y_test = to_categorical(y_test,10)\n",
    "\n",
    "model.fit(x_train,y_train,batch_size=32,epochs=5)\n",
    "\n",
    "predictions=model.predict(x_test)\n",
    "for i in range(5):\n",
    "  print(y_test[i])\n",
    "  print(predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dedf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn \n",
    "#mnist dataset\n",
    "### Implemntation of Convolutional Neural Network (CNN) to predict the numbers from hand written images.\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "x_train.shape\n",
    "x_test.shape\n",
    "plt.imshow(x_train[2])\n",
    "print(y_train[2])\n",
    "plt.imshow(x_test[7])\n",
    "print(y_test[7])\n",
    "x_train = x_train.reshape(60000,28,28,1)\n",
    "x_train\n",
    "x_test = x_test.reshape(10000,28,28,1)\n",
    "y_train[0]\n",
    "y_train = to_categorical(y_train)\n",
    "y_train[0]\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "cnnmodel=Sequential()\n",
    "from keras.layers.convolutional.base_conv import Conv\n",
    "cnnmodel.add(Conv2D(64,kernel_size=3,activation=\"relu\",input_shape=(28,28,1)))\n",
    "cnnmodel.add(Conv2D(32,kernel_size=3,activation=\"relu\"))\n",
    "cnnmodel.add(Flatten())\n",
    "cnnmodel.add(Dense(10,activation=\"softmax\"))\n",
    "cnnmodel.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=\"accuracy\")\n",
    "cnnmodel.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=3)\n",
    "\n",
    "print(cnnmodel.predict(x_test[:3]))\n",
    "print(y_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2b5229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regularization\n",
    "#Implementing regularisation to avoid overfitting in binary classification\n",
    "from sklearn.datasets import make_moons\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "x, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
    "x.shape\n",
    "y.shape\n",
    "x_train, x_test = x[:30,:],x[30:,:]\n",
    "y_train, y_test = y[:30],y[30:]\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2, activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=\"accuracy\")\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=4000)\n",
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history[\"accuracy\"], label=\"train\")\n",
    "pyplot.plot(history.history[\"val_accuracy\"], label=\"test\")\n",
    "pyplot.legend()\n",
    "\n",
    "#L2\n",
    "from keras.regularizers import l2\n",
    "model_l2 = Sequential()\n",
    "model_l2.add(Dense(500, input_dim=2, activation=\"relu\", kernel_regularizer=l2(0.001)))\n",
    "model_l2.add(Dense(1,activation=\"sigmoid\"))\n",
    "model_l2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=\"accuracy\")\n",
    "history2 = model_l2.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=4000)\n",
    "\n",
    "from matplotlib import pyplot\n",
    "pyplot.plot(history2.history[\"accuracy\"], label=\"train\")\n",
    "pyplot.plot(history2.history[\"val_accuracy\"], label=\"test\")\n",
    "pyplot.legend()\n",
    "\n",
    "#L1\n",
    "from keras.regularizers import l1\n",
    "model_l1 = Sequential()\n",
    "model_l1.add(Dense(500, input_dim=2, activation=\"relu\", kernel_regularizer=l1(0.001)))\n",
    "model_l1.add(Dense(1,activation=\"sigmoid\"))\n",
    "model_l1.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=\"accuracy\")\n",
    "history3 = model_l1.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=2000)\n",
    "\n",
    "from matplotlib import pyplot\n",
    "pyplot.plot(history3.history[\"accuracy\"], label=\"train\")\n",
    "pyplot.plot(history3.history[\"val_accuracy\"], label=\"test\")\n",
    "pyplot.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c61d5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#early stopping\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "df = keras.datasets.fashion_mnist\n",
    "df\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "trn_images, valid_images, trn_labels, valid_labels = train_test_split(train_images, train_labels, test_size=0.3, random_state=2)\n",
    "trn_images.shape\n",
    "trn_labels.shape\n",
    "\n",
    " trn_images = trn_images/255.0\n",
    "test_images = test_images/255.0\n",
    "valid_images = valid_images/255.0\n",
    "\n",
    "model1 = keras.models.Sequential()\n",
    "model1.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "model1.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model1.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model2 = keras.models.Sequential()\n",
    "model2.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "model2.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model2.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model1.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model2.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model1.fit(trn_images, trn_labels, epochs=50, validation_data=(valid_images, valid_labels))\n",
    "\n",
    "model1.evaluate(test_images, test_labels)\n",
    "\n",
    "df = pd.DataFrame(history.history)\n",
    "ind=[1,3]\n",
    "df.iloc[:,ind].plot(figsize=(8,5))\n",
    "plt.grid=(True)\n",
    "plt.gca().set_ylim(0.8,0.98) #set vertical range to [0.5-1]\n",
    "plt.show()\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(patience=4, restore_best_weights=True)\n",
    "history1 = model2.fit(trn_images, trn_labels, epochs=50, validation_data=(valid_images, valid_labels), callbacks=[callback])\n",
    "\n",
    "df = pd.DataFrame(history1.history)\n",
    "ind=[1,3]\n",
    "df.iloc[:,ind].plot(figsize=(8,5))\n",
    "plt.grid=(True)\n",
    "plt.gca().set_ylim(0.8,0.98) #set vertical range to [0.5-1]\n",
    "plt.show()\n",
    "\n",
    "model2.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd8b61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#google stock\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "training_data = pd.read_csv(\"/content/drive/MyDrive/dsai/SEM 3/DL/datasets/Google_Stock_Price_Train.csv\")\n",
    "training_data.head()\n",
    "training_data.shape\n",
    "train_data = training_data.iloc[:,1:2].values\n",
    "train_data\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "train_set_scaled = sc.fit_transform(train_data)\n",
    "train_set_scaled\n",
    "x_train=[]\n",
    "y_train=[]\n",
    "for i in range(60,1258):\n",
    "  x_train.append(train_set_scaled[i-60:i, 0])\n",
    "  y_train.append(train_set_scaled[i,0])\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "x_train\n",
    "y_train\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1],1))\n",
    "x_train\n",
    "\n",
    "regressor_stock = Sequential()\n",
    "regressor_stock.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))\n",
    "regressor_stock.add(Dropout(0.2))\n",
    "regressor_stock.add(LSTM(units=50, return_sequences=True))\n",
    "regressor_stock.add(Dropout(0.2))\n",
    "regressor_stock.add(LSTM(units=50, return_sequences=True))\n",
    "regressor_stock.add(Dropout(0.2))\n",
    "regressor_stock.add(LSTM(units=50))\n",
    "regressor_stock.add(Dropout(0.2))\n",
    "regressor_stock.add(Dense(units=1))\n",
    "regressor_stock.compile(optimizer=\"adam\", loss=\"mean_absolute_error\")\n",
    "regressor_stock.fit(x_train, y_train, epochs=100, batch_size=32)\n",
    "testing_data = pd.read_csv(\"/content/drive/MyDrive/dsai/SEM 3/DL/datasets/Google_Stock_Price_Test.csv\")\n",
    "testing_data.head()\n",
    "testing_data.shape\n",
    "real_stock_price = testing_data.iloc[:,1:2].values\n",
    "dataset_total = pd.concat((training_data[\"Open\"], testing_data[\"Open\"]), axis=0)\n",
    "dataset_total\n",
    "inputs = dataset_total[len(dataset_total) - len(testing_data) - 60:].values\n",
    "inputs\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "inputs\n",
    "\n",
    "x_test = []\n",
    "for i in range(60,80):\n",
    "  x_test.append(inputs[i-60:i,0])\n",
    "x_test = np.array(x_test)\n",
    "x_test\n",
    "x_test = np.reshape(x_test,(x_test.shape[0],x_test.shape[1],1))\n",
    "x_test\n",
    "predicted_stock_price = regressor_stock.predict(x_test)\n",
    "real_predictions = sc.inverse_transform(predicted_stock_price)\n",
    "plt.plot(real_stock_price, color=\"red\", label=\"Real Price\")\n",
    "plt.plot(real_predictions, color=\"green\", label=\"Predicted Price\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97d1603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary classiication\n",
    "import pandas as pd\n",
    "#df = pd.read_csv('diabetes.csv', header=None, names = ['no_of_preg','glucose_level','bp','skinthickness',\n",
    "                                                     #'insulin','BMI','pedigree','age','class'])\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "df.head()\n",
    "df.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "classifiernn = Sequential()\n",
    "classifiernn.add(Dense(units=10, activation='relu', input_dim=8))\n",
    "classifiernn.add(Dense(units=8, activation='relu'))\n",
    "classifiernn.add(Dense(units=1, activation='sigmoid'))\n",
    "classifiernn.compile(loss='binary_crossentropy', optimizer='adam', metrics='accuracy')\n",
    "x = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "x.head()\n",
    "y.head()\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.25, random_state=1)\n",
    "x_train.shape\n",
    "classifiernn.fit(x_train, y_train, epochs=500, batch_size=20) #576/20 = 29\n",
    "predictions = classifiernn.predict(x_test)\n",
    "predictions.shape\n",
    "class_label=[]\n",
    "for i in range(192):\n",
    "    if(predictions[i]>0.5):\n",
    "        class_label.append(1)\n",
    "    else:\n",
    "        class_label.append(0)\n",
    "class_label\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, class_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbba19f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiclass classifiation wine dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "wine_data = load_wine()\n",
    "x = wine_data.data\n",
    "y = wine_data.target\n",
    "df = pd.DataFrame(wine_data.data, columns = wine_data.feature_names)\n",
    "df.head()\n",
    "df2 = pd.DataFrame(wine_data.target, columns = [\"Target\"])\n",
    "df2.sample(10)\n",
    "from keras.utils import np_utils\n",
    "encoded_y = np_utils.to_categorical(df2)\n",
    "encoded_y\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=13, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "#adam = mini batch gradient descent algo\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=\"accuracy\")\n",
    "model.fit(df, encoded_y, epochs=100, batch_size=10)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df,encoded_y,test_size=0.25,random_state=2)\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred\n",
    "\n",
    "def vec2scalar(list_):\n",
    "    pred = []\n",
    "    for i in list_:\n",
    "        val = [round(j,0) for j in i]\n",
    "        if val[0]==1.0:\n",
    "            pred.append(0)\n",
    "        elif val[1]==1.0:\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(2)\n",
    "    return pred\n",
    "print(vec2scalar(y_pred))\n",
    "print(vec2scalar(y_test))\n",
    "_, accuracy = model.evaluate(df, encoded_y)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aff1246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regression using fnn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(0)\n",
    "x = np.random.rand(1000,3) #vectors will be generated\n",
    "x[0:5]\n",
    "def true_func(x):\n",
    "  return np.sin(1.5 * np.pi * x[:,0]) + np.cos(1.5 * np.pi*x[:,1]) + 2 * x[:,2]\n",
    "y = true_func(x)\n",
    "y[0:5]\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2,random_state=1)\n",
    "model = Sequential()\n",
    "model.add(Dense(15, input_dim=3, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"linear\"))\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=\"mean_absolute_error\")\n",
    "model.fit(xtrain, ytrain, epochs=150, batch_size=30)\n",
    "predictions = model.predict(xtest)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(ytest, predictions)\n",
    "\n",
    "#3 column dataset\n",
    "df = pd.DataFrame(np.random.randint(0, 5, size=(20, 3)), columns=['mass', 'acceleration', 'force'])\n",
    "df[\"force\"] = df[\"mass\"]*df[\"acceleration\"]\n",
    "print(df)\n",
    "x = df.iloc[:,:2]\n",
    "y = df.iloc[:,2]\n",
    "print(\"x:\",x)\n",
    "print(\"y:\",y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state = 1)\n",
    "y_train\n",
    "model = Sequential()\n",
    "model.add(Dense(15, input_dim=2, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"linear\"))\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=\"mean_absolute_error\")\n",
    "model.fit(x_train, y_train, epochs=1000, batch_size=5)\n",
    "predictions = model.predict(x_test)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
